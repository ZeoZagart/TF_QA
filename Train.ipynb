{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.NQModel import NQModel\n",
    "from Model.LossFn import LossFn\n",
    "import torch\n",
    "import time\n",
    "import sklearn\n",
    "import datetime\n",
    "import Model.datasetutils as datasetutils\n",
    "import Model.tensorboardutils as boardutils\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs/NQ_TIME:20827'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorBoardLocation = 'runs/NQ_TIME:{}'.format(int((time.time() - 1583988084)/60))\n",
    "TensorBoardLocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1 # no loop \n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "writer = tensorboard.SummaryWriter(TensorBoardLocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdb412ec7504cb7a15fac9fa9f4911a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "traingen, validgen = datasetutils.get_dataset(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(566456, 188819)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_steps = len(traingen)\n",
    "val_steps = len(validgen)\n",
    "num_steps, val_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mNQ_TIME:20799\u001b[m\u001b[m \u001b[34mNQ_TIME:20819\u001b[m\u001b[m \u001b[34mNQ_TIME:20827\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NQModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = transformers.AdamW(model.parameters())\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optim, num_warmup_steps=100, num_training_steps=800,num_cycles=0.5, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnswerTypes = ['Wrong Ans', 'Short Ans', 'Yes No']\n",
    "YesNoLabels = ['No', 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_confusion_matrix(ATMatrix, YNMatrix, StartM, EndM, output, target) : \n",
    "    predsT = output[0].argmax(dim = 1)\n",
    "    truthT = target[0].argmax(dim = 1)\n",
    "\n",
    "    for x, y in zip(predsT, truthT) : \n",
    "        ATMatrix[x][y] += 1\n",
    "\n",
    "\n",
    "    predsYN = (torch.sigmoid(output[3].flatten()) >= 0.5) + 1 -1\n",
    "    truthYN = target[3].flatten()\n",
    "\n",
    "    for x, y in zip(predsYN, truthYN) : \n",
    "        YNMatrix[x][y] += 1    \n",
    "\n",
    "\n",
    "    start01 = (torch.sigmoid(output[1].flatten()) >= 0.5) +1 -1\n",
    "    end01   = (torch.sigmoid(output[2].flatten()) >= 0.5) +1 -1\n",
    "\n",
    "    startcm = sklearn.metrics.confusion_matrix(target[1].flatten().numpy(), start01)\n",
    "    endcm   = sklearn.metrics.confusion_matrix(target[2].flatten().numpy(), end01)\n",
    "\n",
    "    StartM += torch.from_numpy(startcm)\n",
    "    EndM   += torch.from_numpy(endcm)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(matrix, labels, name, step): \n",
    "    opfigure = boardutils.confusion_matrix_image(matrix.numpy(), labels)\n",
    "    writer.add_figure(name, opfigure, step)\n",
    "    \n",
    "def log_matrices(AnsTypeM, YNM, StM, EndM, call_type, steps):\n",
    "    log_confusion_matrix(AnsTypeM, AnswerTypes, \"Answer type confusion matrix\" + call_type, steps)\n",
    "    log_confusion_matrix(YNM, YesNoLabels, \"Yes No confusion matrix\" + call_type, steps)\n",
    "    log_confusion_matrix(StM, YesNoLabels, \"Start confusion matrix\" + call_type, steps)\n",
    "    log_confusion_matrix(EndM, YesNoLabels, \"End confusion matrix\" + call_type, steps) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_num) : \n",
    "    model.eval()\n",
    "    \n",
    "    ValAnswerTypeMatrix = torch.zeros([3, 3], requires_grad = False)\n",
    "    ValYesNoMatrix      = torch.zeros([2, 2], requires_grad = False)\n",
    "    ValStartMatrix      = torch.zeros([2, 2], requires_grad = False)\n",
    "    ValEndMatrix        = torch.zeros([2, 2], requires_grad = False)\n",
    "    \n",
    "    at_l, start_l, end_l, yn_l = 0,0,0,0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inp_id, inp_type, inp_mask, ans_type, start, end, yes_no in tqdm(validgen) : \n",
    "            output = model(inp_id.squeeze().to(device), inp_mask.squeeze().to(device), inp_type.squeeze().to(device))  \n",
    "\n",
    "            detached_output = (output[0].detach().cpu(), output[1].detach().cpu(), output[2].detach().cpu(), output[3].detach().cpu())\n",
    "            update_confusion_matrix(ValAnswerTypeMatrix, ValYesNoMatrix, ValStartMatrix, ValEndMatrix, detached_output, (ans_type, start, end, yes_no))\n",
    "\n",
    "            ## Calculate Loss\n",
    "            at_l += LossFn.loss_AT(detached_output[0], ans_type.squeeze().argmax(1)).item()\n",
    "            start_l += LossFn.loss_start(detached_output[1], start.squeeze().type(torch.FloatTensor)).item()\n",
    "            end_l += LossFn.loss_end(detached_output[2], end.squeeze().type(torch.FloatTensor)).item()\n",
    "            yn_l += LossFn.loss_yes_no(detached_output[3], yes_no.squeeze()).item()\n",
    "            \n",
    "            \n",
    "    ## Save loss values\n",
    "    writer.add_scalars('Loss values Validation',\n",
    "        {\"AT_loss_val\" : at_l,\"Start_loss_val\":start_l, \"End_loss_val\":end_l, \"Yes_no_loss_val\":yn_l},\n",
    "        val_num, time.time())\n",
    "\n",
    "    log_matrices(ValAnswerTypeMatrix, ValYesNoMatrix, ValStartMatrix, ValEndMatrix, \" eval\", val_num)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train() : \n",
    "    AnswerTypeMatrix = torch.zeros([3,3], requires_grad = False)\n",
    "    YesNoMatrix      = torch.zeros([2,2], requires_grad = False)\n",
    "    StartMatrix      = torch.zeros([2,2], requires_grad = False)\n",
    "    EndMatrix        = torch.zeros([2,2], requires_grad = False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    steps = -1\n",
    "\n",
    "    for inp_id, inp_type, inp_mask, ans_type, start, end, yes_no in tqdm(traingen) : \n",
    "        steps += 1\n",
    "        optim.zero_grad()\n",
    "        output = model(inp_id.squeeze().to(device), inp_mask.squeeze().to(device), inp_type.squeeze().to(device))\n",
    "        \n",
    "        detached_output = (output[0].detach().cpu(), output[1].detach().cpu(), output[2].detach().cpu(), output[3].detach().cpu())\n",
    "        ## Calculate Confusion Matrix\n",
    "        update_confusion_matrix(AnswerTypeMatrix, YesNoMatrix, StartMatrix, EndMatrix, detached_output, (ans_type, start, end, yes_no))\n",
    "        if steps%5 == 0: log_matrices(AnswerTypeMatrix, YesNoMatrix, StartMatrix, EndMatrix, \" train\", steps)\n",
    "\n",
    "        ## Calculate Loss\n",
    "        AT_loss = LossFn.loss_AT(output[0], ans_type.squeeze().argmax(1).to(device))\n",
    "        Start_loss = LossFn.loss_start(output[1], start.squeeze().type(torch.FloatTensor).to(device))\n",
    "        End_loss = LossFn.loss_end(output[2], end.squeeze().type(torch.FloatTensor).to(device))\n",
    "        Yes_no_loss = LossFn.loss_yes_no(output[3], yes_no.squeeze().to(device))\n",
    "        \n",
    "        ## Update model params and optim/sched\n",
    "        total_loss = AT_loss + Start_loss + End_loss + Yes_no_loss\n",
    "        total_loss.backward()\n",
    "\n",
    "        ## Save loss values\n",
    "        writer.add_scalars('Loss values',\n",
    "            {\"AT_loss\" : AT_loss.item(),\"Start_loss\":Start_loss.item(), \"End_loss\":End_loss.item(), \"Yes_no_loss\":Yes_no_loss.item()},\n",
    "            steps, time.time())\n",
    "\n",
    "        cur_time = time.time() - start_time\n",
    "        expected_time = (cur_time*num_steps)/(steps + 1)\n",
    "        print (\"elapsed time : \" + str(time.time() - start_time)+ \" : expected time : \" +  str(expected_time))\n",
    "\n",
    "        optim.step()\n",
    "        scheduler.step()     \n",
    "        \n",
    "        if steps%20 == 0 : validate(steps/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f67b2ae11948a29349736cbf024d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=566456), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time : 100.24083876609802 : expected time : 56782019.0268898\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73fc53414e7440ef964dce55fdf48b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=188819), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time : 272.0269949436188 : expected time : 77045649.50153732\n",
      "elapsed time : 388.9010429382324 : expected time : 73431767.47933324\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-179e53c4ef51>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minp_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myes_no\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraingen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0, 1, 2], requires_grad=False, dtype=torch.half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dtype.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
