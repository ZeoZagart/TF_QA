{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.NQModel import NQModel\n",
    "from Model.LossFn import LossFn\n",
    "import torch\n",
    "import time\n",
    "import sklearn\n",
    "import datetime\n",
    "import Model.datasetutils as datasetutils\n",
    "import Model.tensorboardutils as boardutils\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorBoardLocation = 'runs/NQ_TIME:{}'.format(int((time.time() - 1583988084)/60))\n",
    "TensorBoardLocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1 # no loop \n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "writer = tensorboard.SummaryWriter(TensorBoardLocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen, validgen = datasetutils.get_dataset(num_workers = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = len(traingen)\n",
    "val_steps = len(validgen)\n",
    "num_steps, val_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NQModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = transformers.AdamW(model.parameters())\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optim, num_warmup_steps=100, num_training_steps=800,num_cycles=0.5, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnswerTypes = ['Wrong Ans', 'Short Ans', 'Yes No']\n",
    "YesNoLabels = ['No', 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_confusion_matrix(ATMatrix, YNMatrix, StartM, EndM, output, target) : \n",
    "    predsT = output[0].argmax(dim = 1)\n",
    "    truthT = target[0].argmax(dim = 1)\n",
    "\n",
    "    for x, y in zip(predsT, truthT) : \n",
    "        ATMatrix[x][y] += 1\n",
    "\n",
    "\n",
    "    predsYN = (torch.sigmoid(output[3].flatten()) >= 0.5) + 1 -1\n",
    "    truthYN = target[3].flatten()\n",
    "\n",
    "    for x, y in zip(predsYN, truthYN) : \n",
    "        YNMatrix[x][y] += 1    \n",
    "\n",
    "\n",
    "    start01 = (torch.sigmoid(output[1].flatten()) >= 0.5) +1 -1\n",
    "    end01   = (torch.sigmoid(output[2].flatten()) >= 0.5) +1 -1\n",
    "\n",
    "    startcm = sklearn.metrics.confusion_matrix(target[1].flatten().numpy(), start01)\n",
    "    endcm   = sklearn.metrics.confusion_matrix(target[2].flatten().numpy(), end01)\n",
    "\n",
    "    StartM += torch.from_numpy(startcm)\n",
    "    EndM   += torch.from_numpy(endcm)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(matrix, labels, name, step): \n",
    "    opfigure = boardutils.confusion_matrix_image(matrix.numpy(), labels)\n",
    "    writer.add_figure(name, opfigure, step)\n",
    "    \n",
    "def log_matrices(AnsTypeM, YNM, StM, EndM, call_type, steps):\n",
    "    log_confusion_matrix(AnsTypeM, AnswerTypes, \"Answer type confusion matrix\" + call_type, steps)\n",
    "    log_confusion_matrix(YNM, YesNoLabels, \"Yes No confusion matrix\" + call_type, steps)\n",
    "    log_confusion_matrix(StM, YesNoLabels, \"Start confusion matrix\" + call_type, steps)\n",
    "    log_confusion_matrix(EndM, YesNoLabels, \"End confusion matrix\" + call_type, steps) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = LossFn(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_num) : \n",
    "    model.eval()\n",
    "    \n",
    "    ValAnswerTypeMatrix = torch.zeros([3, 3], requires_grad = False)\n",
    "    ValYesNoMatrix      = torch.zeros([2, 2], requires_grad = False)\n",
    "    ValStartMatrix      = torch.zeros([2, 2], requires_grad = False)\n",
    "    ValEndMatrix        = torch.zeros([2, 2], requires_grad = False)\n",
    "    \n",
    "    at_l, start_l, end_l, yn_l = 0,0,0,0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for bert_enc, ans_type, start, end, yes_no in tqdm(validgen) : \n",
    "            output = model(bert_enc.to(device))  \n",
    "\n",
    "            detached_output = (output[0].detach().cpu(), output[1].detach().cpu(), output[2].detach().cpu(), output[3].detach().cpu())\n",
    "            update_confusion_matrix(ValAnswerTypeMatrix, ValYesNoMatrix, ValStartMatrix, ValEndMatrix, detached_output, (ans_type, start, end, yes_no))\n",
    "\n",
    "            ## Calculate Loss\n",
    "            at_l += loss.ans_type(detached_output[0], ans_type.squeeze().argmax(1)).item()\n",
    "            start_l += loss.start(detached_output[1], start.squeeze().type(torch.FloatTensor)).item()\n",
    "            end_l += loss.end(detached_output[2], end.squeeze().type(torch.FloatTensor)).item()\n",
    "            yn_l += loss.yes_no(detached_output[3], yes_no.squeeze()).item()\n",
    "            \n",
    "            \n",
    "    ## Save loss values\n",
    "    writer.add_scalars('Loss values Validation',\n",
    "        {\"AT_loss_val\" : at_l,\"Start_loss_val\":start_l, \"End_loss_val\":end_l, \"Yes_no_loss_val\":yn_l},\n",
    "        val_num, time.time())\n",
    "\n",
    "    log_matrices(ValAnswerTypeMatrix, ValYesNoMatrix, ValStartMatrix, ValEndMatrix, \" eval\", val_num)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train() : \n",
    "    AnswerTypeMatrix = torch.zeros([3,3], requires_grad = False)\n",
    "    YesNoMatrix      = torch.zeros([2,2], requires_grad = False)\n",
    "    StartMatrix      = torch.zeros([2,2], requires_grad = False)\n",
    "    EndMatrix        = torch.zeros([2,2], requires_grad = False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    steps = -1\n",
    "\n",
    "    for bert_enc, ans_type, start, end, yes_no in tqdm(traingen) : \n",
    "        steps += 1\n",
    "        optim.zero_grad()\n",
    "        output = model(bert_enc.to(device).squeeze())\n",
    "\n",
    "        ## Calculate Loss\n",
    "        AT_loss = loss.ans_type(output[0], ans_type.squeeze().argmax(1).to(device))\n",
    "        Start_loss = loss.start(output[1], start.squeeze().type(torch.FloatTensor).to(device))\n",
    "        End_loss = loss.end(output[2], end.squeeze().type(torch.FloatTensor).to(device))\n",
    "        Yes_no_loss = loss.yes_no(output[3], yes_no.squeeze().to(device))\n",
    "\n",
    "        ## Update model params and optim/sched\n",
    "        total_loss = AT_loss + Start_loss + End_loss + Yes_no_loss\n",
    "        total_loss.backward()\n",
    "\n",
    "        ## Calculate Confusion Matrix\n",
    "        detached_output = (output[0].detach().cpu(), output[1].detach().cpu(), output[2].detach().cpu(), output[3].detach().cpu())\n",
    "        update_confusion_matrix(AnswerTypeMatrix, YesNoMatrix, StartMatrix, EndMatrix, detached_output, (ans_type, start, end, yes_no))\n",
    "        if steps%5 == 0: log_matrices(AnswerTypeMatrix, YesNoMatrix, StartMatrix, EndMatrix, \" train\", steps)\n",
    "\n",
    "        ## Save loss values\n",
    "        writer.add_scalars('Loss values',\n",
    "            {\"AT_loss\" : AT_loss.item(),\"Start_loss\":Start_loss.item(), \"End_loss\":End_loss.item(), \"Yes_no_loss\":Yes_no_loss.item()},\n",
    "            steps, time.time())\n",
    "\n",
    "        cur_time = time.time() - start_time\n",
    "        expected_time = (cur_time*num_steps)/(steps + 1)\n",
    "        print (\"elapsed time : \" + str(time.time() - start_time)+ \" : expected time : \" +  str(expected_time))\n",
    "\n",
    "        optim.step()\n",
    "        scheduler.step()     \n",
    "        \n",
    "        if steps%20 == 0 : validate(steps/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
