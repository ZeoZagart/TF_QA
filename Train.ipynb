{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.NQModel import NQModel\n",
    "from Model.LossFn import LossFn\n",
    "import torch\n",
    "import time\n",
    "import sklearn\n",
    "import datetime\n",
    "import Model.datasetutils as datasetutils\n",
    "import Model.tensorboardutils as boardutils\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import transformers\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorBoardLocation = 'runs/NQ_TIME:{}'.format(int((time.time() - 1583988084)/60))\n",
    "TensorBoardLocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1 # no loop \n",
    "use_cuda = torch.cuda.is_available()\n",
    "model_device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "bert_device  = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "writer = tensorboard.SummaryWriter(TensorBoardLocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen, validgen = datasetutils.get_dataset(num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = len(traingen)\n",
    "val_steps = len(validgen)\n",
    "num_steps, val_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NQModel().to(model_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr = 0.000005)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=0.0005, epochs=1, steps_per_epoch=len(traingen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnswerTypes = ['Wrong Ans', 'Short Ans', 'Yes No']\n",
    "YesNoLabels = ['No', 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_confusion_matrix(ATMatrix, YNMatrix, StartM, EndM, output, target) : \n",
    "    predsT = output[0].argmax(dim = 1)\n",
    "    truthT = target[0].argmax(dim = 1)\n",
    "\n",
    "    for x, y in zip(predsT, truthT) : \n",
    "        ATMatrix[x][y] += 1\n",
    "\n",
    "\n",
    "    predsYN = (torch.sigmoid(output[3].flatten()) >= 0.5) + 1 -1\n",
    "    truthYN = target[3].flatten()\n",
    "\n",
    "    for x, y in zip(predsYN, truthYN) : \n",
    "        YNMatrix[x][y] += 1    \n",
    "\n",
    "\n",
    "    start01 = (torch.sigmoid(output[1].flatten()) >= 0.5) +1 -1\n",
    "    end01   = (torch.sigmoid(output[2].flatten()) >= 0.5) +1 -1\n",
    "\n",
    "    startcm = sklearn.metrics.confusion_matrix(target[1].flatten().numpy(), start01)\n",
    "    endcm   = sklearn.metrics.confusion_matrix(target[2].flatten().numpy(), end01)\n",
    "\n",
    "    StartM += torch.from_numpy(startcm)\n",
    "    EndM   += torch.from_numpy(endcm)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(matrix, labels, name, step): \n",
    "    opfigure = boardutils.confusion_matrix_image(matrix.numpy(), labels)\n",
    "    writer.add_figure(name, opfigure, step)\n",
    "\n",
    "def log_matrices(AnsTypeM, YNM, StM, EndM, call_type, steps):\n",
    "    log_confusion_matrix(AnsTypeM, AnswerTypes, \"Answer type confusion matrix\" + call_type, steps)\n",
    "    log_confusion_matrix(YNM, YesNoLabels, \"Yes No confusion matrix\" + call_type, steps)\n",
    "    log_confusion_matrix(StM, YesNoLabels, \"Start confusion matrix\" + call_type, steps)\n",
    "    log_confusion_matrix(EndM, YesNoLabels, \"End confusion matrix\" + call_type, steps) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = LossFn(model_device)\n",
    "bert_encoder = BertModel.from_pretrained('bert-base-uncased').to(bert_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnswerTypeMatrix = torch.zeros([3,3], requires_grad = False)\n",
    "YesNoMatrix      = torch.zeros([2,2], requires_grad = False)\n",
    "StartMatrix      = torch.zeros([2,2], requires_grad = False)\n",
    "EndMatrix        = torch.zeros([2,2], requires_grad = False)\n",
    "   \n",
    "ValAnswerTypeMatrix = torch.zeros([3, 3], requires_grad = False)\n",
    "ValYesNoMatrix      = torch.zeros([2, 2], requires_grad = False)\n",
    "ValStartMatrix      = torch.zeros([2, 2], requires_grad = False)\n",
    "ValEndMatrix        = torch.zeros([2, 2], requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_l, start_l, end_l, yn_l = 0, 0, 0, 0\n",
    "def validate_step(inp_ids, mask, token_types, ans_type, start, end, yes_no): \n",
    "    global at_l, start_l, end_l, yn_l\n",
    "    encoding, _ = bert_encoder(inp_ids.to(bert_device), mask.to(bert_device), token_types.to(bert_device))\n",
    "    output = model(encoding)  \n",
    "    # output = model(encoding.to(model_device))  bert and model devices are same\n",
    "\n",
    "    ## Calculate Loss\n",
    "    at_l += loss.ans_type(output[0], ans_type.argmax(1).to(model_device)).item()\n",
    "    start_l += loss.start(output[1], start.type(torch.FloatTensor).to(model_device)).item()\n",
    "    end_l += loss.end(output[2], end.type(torch.FloatTensor).to(model_device)).item()\n",
    "    yn_l += loss.yes_no(output[3], yes_no.to(model_device)).item()\n",
    "\n",
    "    detached_output = (output[0].detach().cpu(), output[1].detach().cpu(), output[2].detach().cpu(), output[3].detach().cpu())\n",
    "    update_confusion_matrix(ValAnswerTypeMatrix, ValYesNoMatrix, ValStartMatrix, ValEndMatrix, detached_output, (ans_type.detach(), start.detach(), end.detach(), yes_no.detach()))\n",
    "\n",
    "def validate(val_num) : \n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    ctr = 0\n",
    "    with torch.no_grad():\n",
    "        for inp_ids, mask, token_types, ans_type, start, end, yes_no in tqdm(validgen) : \n",
    "            ctr += 1\n",
    "            inp_ids, mask, token_types, ans_type, start, end, yes_no = inp_ids.squeeze(), mask.squeeze(), token_types.squeeze(), ans_type.squeeze(), start.squeeze(), end.squeeze(), yes_no.squeeze()\n",
    "\n",
    "            validate_step(inp_ids, mask, token_types, ans_type, start, end, yes_no)\n",
    "            if ctr >= 1: break\n",
    "            \n",
    "    print (\"time : \" + str(time.time() - start_time) + \" steps : \" + str(ctr))     \n",
    "    ## Save loss values\n",
    "    writer.add_scalars('Loss values Validation',\n",
    "        {\"AT_loss_val\" : at_l,\"Start_loss_val\":start_l, \"End_loss_val\":end_l, \"Yes_no_loss_val\":yn_l},\n",
    "        val_num, time.time())\n",
    "\n",
    "    log_matrices(ValAnswerTypeMatrix, ValYesNoMatrix, ValStartMatrix, ValEndMatrix, \" eval\", val_num)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inp_ids, mask, token_types, ans_type, start, end, yes_no, steps): \n",
    "#     global writer, optim, scheduler, bert_encoder, model\n",
    "    with torch.no_grad() :\n",
    "        encoding, _ = bert_encoder(inp_ids.to(bert_device), mask.to(bert_device), token_types.to(bert_device))\n",
    "\n",
    "    output = model(encoding) \n",
    "#     print (\"1 :\" + str(torch.cuda.memory_allocated()))\n",
    "    # output = model(encoding.to(model_device))  bert and model devices are same\n",
    "    \n",
    "    ## Calculate Loss\n",
    "    AT_loss = loss.ans_type(output[0], ans_type.argmax(1).to(model_device))\n",
    "    Start_loss = loss.start(output[1], start.type(torch.FloatTensor).to(model_device))\n",
    "    End_loss = loss.end(output[2], end.type(torch.FloatTensor).to(model_device))\n",
    "    Yes_no_loss = loss.yes_no(output[3], yes_no.to(model_device))\n",
    "#     print (\"2 :\" + str(torch.cuda.memory_allocated()))\n",
    "    \n",
    "    ## Update model params and optim/sched\n",
    "    (AT_loss + Start_loss + End_loss + Yes_no_loss).backward()\n",
    "#     print (\"3 :\" + str(torch.cuda.memory_allocated()))\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "#     scheduler.step()  \n",
    "    \n",
    "#     print (\"4 :\" + str(torch.cuda.memory_allocated()))\n",
    "    if steps%20 == 0: \n",
    "        ## Calculate Confusion Matrix\n",
    "        detached_output = (output[0].detach().cpu(), output[1].detach().cpu(), output[2].detach().cpu(), output[3].detach().cpu())\n",
    "        update_confusion_matrix(AnswerTypeMatrix, YesNoMatrix, StartMatrix, EndMatrix, detached_output, (ans_type.detach(), start.detach(), end.detach(), yes_no.detach()))\n",
    "        log_matrices(AnswerTypeMatrix, YesNoMatrix, StartMatrix, EndMatrix, \" train\", steps)\n",
    "    \n",
    "    writer.add_scalars('Loss values',\n",
    "        {\"AT_loss\" : AT_loss.item(),\"Start_loss\":Start_loss.item(), \"End_loss\":End_loss.item(), \"Yes_no_loss\":Yes_no_loss.item()},\n",
    "        steps, time.time())\n",
    "       \n",
    "#     print (\"5 :\" + str(torch.cuda.memory_allocated())) \n",
    "\n",
    "def train() : \n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    steps = -1\n",
    "\n",
    "    for inp_ids, mask, token_types, ans_type, start, end, yes_no in tqdm(traingen) : \n",
    "        inp_ids, mask, token_types, ans_type, start, end, yes_no = inp_ids.squeeze(), mask.squeeze(), token_types.squeeze(), ans_type.squeeze(), start.squeeze(), end.squeeze(), yes_no.squeeze()\n",
    "\n",
    "        steps += 1\n",
    "        \n",
    "        train_step(inp_ids, mask, token_types, ans_type, start, end, yes_no,steps)\n",
    "        \n",
    "        if (steps%1000 == 0): \n",
    "            cur_time = time.time() - start_time\n",
    "            expected_time = (cur_time*num_steps)/(steps + 1)\n",
    "            print (\"elapsed time : \" + str(time.time() - start_time)+ \" : expected time : \" +  str(expected_time))\n",
    "            if (steps%10000) : validate(steps/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
